{
  "owner": "kvcache-ai",
  "repo": "kvcache-ai/ktransformers",
  "name": "ktransformers",
  "full_name": "kvcache-ai/ktransformers",
  "description": "A Flexible Framework for Experiencing Cutting-edge LLM Inference Optimizations",
  "homepage": "https://kvcache-ai.github.io/ktransformers/",
  "language": "Python",
  "license": "Apache-2.0",
  "topics": [],
  "default_branch": "main",
  "archived": false,
  "disabled": false,
  "created_at": "2024-07-26T07:18:28Z",
  "pushed_at": "2025-11-10T08:09:01Z",
  "size": 37008,
  "stars_now": 15534,
  "forks": 1124,
  "open_issues": 642,
  "subscribers": 111,
  "watchers": 15534,
  "html_url": "https://github.com/kvcache-ai/ktransformers",
  "api_url": "https://api.github.com/repos/kvcache-ai/ktransformers",
  "fetched_at": "2025-11-10T08:31:34.952Z",
  "contributor_locations": {},
  "contributor_locations_updated_at": "2025-11-11T11:35:40.547Z"
}